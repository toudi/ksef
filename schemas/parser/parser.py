from collections import defaultdict
from os import listdir, makedirs
from os.path import dirname
from subprocess import call

import xmlschema
from xmlschema.validators.groups import XsdGroup

# there used to be an utterly hideous go program that I wrote for extracting
# information from the xsd schemas. It did the job, but the JPK was more
# complex and it also imported external schemas that were required. I gave up
# but then saw that there was this wonderful xmlschema project and thought
# I'd give it a go since the only thing that I actually need is to generate
# a go source code that would contain metainformation about the xsd schema.
# here we go:


def schema_nodes(schema: xmlschema.XMLSchema):
    nodes = defaultdict(list)
    # dict where the keys are full paths to the node
    # and values are types of the node (e.g. TKwotaC)
    required = {}
    # list of full paths to the array nodes
    array_nodes = set()

    def walk_element(xsd_element, path):
        xsd_type = xsd_element.type

        # Only complex types can have children
        if not xsd_type.is_complex():
            return

        model = xsd_type.content

        # Only groups (sequence / choice / all) contain elements
        if not isinstance(model, XsdGroup):
            return

        for child in model.iter_elements():
            # we'll decide what to do with required fields outside of this function
            # here let's just report it.
            if child.min_occurs > 0:
                required[f"{path}.{child.local_name}"] = child.type.local_name

            nodes[path].append(child.local_name)

            # we need to know which elements are actually arrays - that is
            # necesary when we call Node.ToWriter function that actually
            # renders the content of XML
            if child.max_occurs is None or child.max_occurs > 1:
                array_nodes.add(path + "." + child.local_name)

            walk_element(child, f"{path}.{child.local_name}")

    for element in schema.elements.values():
        walk_element(element, element.local_name)

    return nodes, required, array_nodes


JPK_REQUIRED_FIELDS = {
    "prefixes": [
        # this is a subset of fields that are required.
        # basically, some of the fields that JPK makes mandatory we fill out anyway and so
        # there is no real need to pollute the end file with them. let's stick to the
        # ones that we care about
        "JPK.Deklaracja.PozycjeSzczegolowe",
        "JPK.Ewidencja.SprzedazWiersz",
        "JPK.Ewidencja.ZakupWiersz",
    ],
    "defaults": {
        # consequence of the above is that the parser will tell us about required fields
        # and their types. so we will initialize the JPK document with these zero values
        # which will eventually get overriden. if not, they would stay as zeroes and
        # everyone would be happy.
        "TKwotaC": "0",
        "TKwotaCNieujemna": "0",
        "TKwotowy": "0",
    },
}

TARGET_DIRS = {
    "FA": "../../internal/sei/generators",
    "JPK": "../../internal/invoicesdb/jpk/generators",
}

# ironically, writing the formatting part took longer than the xsd traversal
# part lol. I suppose it would be easier if I'd used some sort of templating
# engine like jinja but that would have just so overkill for the job.
# keep in mind that these files are generated almost never..

if __name__ == "__main__":
    schemas_dir = dirname(__file__) + "/../"
    for schema_file in listdir(schemas_dir):
        if not schema_file.endswith(".xsd"):
            continue

        print(f"processing {schema_file}")

        schema_file_type = schema_file.split("_")[0]

        variable_prefix = schema_file.removesuffix(".xsd")

        package_name = variable_prefix.lower()
        target_dir = TARGET_DIRS[schema_file_type] + "/" + package_name

        makedirs(package_name, exist_ok=True)

        target_filename = target_dir + "/" + "schema_ordering.go"
        with open(target_filename, "w") as ordering_file:
            ordering_file.write(
                (
                    f"package {package_name}\n\n"
                    "// this file was autogenerated. please do NOT modify.\n\n"
                ),
            )
            field_order, required_fields, array_nodes = schema_nodes(
                xmlschema.XMLSchema("../" + schema_file),
            )

            ordering_file.write(
                f"var {variable_prefix}ChildrenOrder = map[string]map[string]int{{\n"
            )

            nth_key = 0
            for node_name, children in field_order.items():
                ordering_file.write(f'  "{node_name}": {{')
                for child_order, child_name in enumerate(children):
                    ordering_file.write(f'"{child_name}": {child_order}')
                    if child_order < len(children) - 1:
                        ordering_file.write(", ")
                ordering_file.write("},\n")
                nth_key += 1

            ordering_file.write("}\n\n")

            if schema_file_type == "JPK":
                if len(required_fields) > 0:
                    ordering_file.write(
                        f"var {variable_prefix}RequiredDefaults = map[string]string{{\n"
                    )
                    for node_name, node_type in required_fields.items():
                        # so basically we're only interested in a subset of
                        # required fields since we're populating some of them knowingly
                        if not filter(
                            lambda prefix: node_name.hasprefix(prefix),
                            JPK_REQUIRED_FIELDS["prefixes"],
                        ):
                            continue
                        if node_type not in JPK_REQUIRED_FIELDS["defaults"]:
                            print(f"unsupported type: {node_name} ({node_type})")
                            continue
                        ordering_file.write(
                            f'"{node_name}": "{JPK_REQUIRED_FIELDS["defaults"][node_type]}",\n'
                        )
                    ordering_file.write("\n}\n\n")

            if len(array_nodes) > 0:
                ordering_file.write(
                    f"var {variable_prefix}ArrayElements = map[string]bool{{\n"
                )
                for node in array_nodes:
                    ordering_file.write(f'"{node}": true,\n')
                ordering_file.write("}")
        print(f"  gofumpt -w {target_filename}\n")
        call(["gofumpt", "-w", target_filename])
